import psycopg2
import numpy as np
from typing import List, Dict, Any, Optional

class VectorSearchManager:
    def __init__(self, connection_string):
        self.connection_string = connection_string
    
    def create_vector_index(self, index_type='ivfflat', lists=100):
        """åˆ›å»ºå‘é‡ç´¢å¼•"""
        try:
            conn = psycopg2.connect(self.connection_string)
            cursor = conn.cursor()
            
            # ç¡®ä¿vectoræ‰©å±•å·²å®‰è£…
            cursor.execute("CREATE EXTENSION IF NOT EXISTS vector;")
            
            if index_type == 'ivfflat':
                index_sql = f"""
                CREATE INDEX IF NOT EXISTS idx_documents_embedding_ivfflat 
                ON documents 
                USING ivfflat (embedding vector_cosine_ops) 
                WITH (lists = {lists});
                """
            elif index_type == 'hnsw':
                index_sql = """
                CREATE INDEX IF NOT EXISTS idx_documents_embedding_hnsw 
                ON documents 
                USING hnsw (embedding vector_cosine_ops) 
                WITH (m = 16, ef_construction = 64);
                """
            else:
                raise ValueError("ç´¢å¼•ç±»å‹å¿…é¡»æ˜¯ 'ivfflat' æˆ– 'hnsw'")
            
            cursor.execute(index_sql)
            conn.commit()
            print(f"âœ… {index_type.upper()} å‘é‡ç´¢å¼•åˆ›å»ºæˆåŠŸ!")
            
        except Exception as e:
            print(f"âŒ ç´¢å¼•åˆ›å»ºå¤±è´¥: {e}")
        finally:
            if conn:
                conn.close()
    
    def search_similar_documents(self, 
                               query_embedding: List[float], 
                               collection_name: str = None,
                               top_k: int = 10,
                               similarity_threshold: float = 0.0) -> List[Dict]:
        """
        ç›¸ä¼¼åº¦æœç´¢
        
        Args:
            query_embedding: æŸ¥è¯¢å‘é‡ï¼ˆ2048ç»´ï¼‰
            collection_name: é›†åˆåç§°è¿‡æ»¤
            top_k: è¿”å›ç»“æœæ•°é‡
            similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼
        """
        # å°†å‘é‡è½¬æ¢ä¸ºPostgreSQLæ ¼å¼
        embedding_str = self._format_vector(query_embedding)
        
        query = """
        SELECT 
            id,
            collection_name,
            subject,
            content,
            metadata,
            created_at,
            1 - (embedding <=> %s) as similarity
        FROM documents 
        {collection_filter}
        {similarity_filter}
        ORDER BY embedding <=> %s
        LIMIT %s
        """
        
        # æ„å»ºæŸ¥è¯¢æ¡ä»¶
        params = [embedding_str]
        conditions = []
        
        if collection_name:
            conditions.append("collection_name = %s")
            params.append(collection_name)
        
        collection_filter = f"WHERE {' AND '.join(conditions)}" if conditions else ""
        
        if similarity_threshold > 0:
            similarity_filter = f"AND 1 - (embedding <=> %s) > %s"
            params.extend([embedding_str, similarity_threshold])
        else:
            similarity_filter = ""
        
        # æ ¼å¼åŒ–æŸ¥è¯¢
        query = query.format(
            collection_filter=collection_filter,
            similarity_filter=similarity_filter
        )
        params.extend([embedding_str, top_k])
        
        try:
            conn = psycopg2.connect(self.connection_string)
            cursor = conn.cursor()
            
            cursor.execute(query, tuple(params))
            results = cursor.fetchall()
            
            # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
            columns = [desc[0] for desc in cursor.description]
            documents = []
            
            for row in results:
                doc = dict(zip(columns, row))
                documents.append(doc)
            
            return documents
            
        except Exception as e:
            print(f"âŒ æœç´¢å¤±è´¥: {e}")
            return []
        finally:
            if conn:
                conn.close()
    
    def _format_vector(self, embedding: List[float]) -> str:
        """å°†Pythonåˆ—è¡¨æ ¼å¼åŒ–ä¸ºPostgreSQLå‘é‡å­—ç¬¦ä¸²"""
        if len(embedding) != 2048:
            raise ValueError(f"å‘é‡ç»´åº¦å¿…é¡»æ˜¯2048ï¼Œå½“å‰æ˜¯{len(embedding)}")
        
        return '[' + ','.join(map(str, embedding)) + ']'
    
    def batch_search(self, 
                    query_embeddings: List[List[float]], 
                    collection_name: str = None,
                    top_k: int = 5) -> Dict[int, List[Dict]]:
        """æ‰¹é‡ç›¸ä¼¼åº¦æœç´¢"""
        results = {}
        
        for i, embedding in enumerate(query_embeddings):
            similar_docs = self.search_similar_documents(
                embedding, collection_name, top_k
            )
            results[i] = similar_docs
        
        return results
    
    def get_index_info(self):
        """è·å–ç´¢å¼•ä¿¡æ¯"""
        try:
            conn = psycopg2.connect(self.connection_string)
            cursor = conn.cursor()
            
            # æŸ¥è¯¢ç´¢å¼•ä¿¡æ¯
            cursor.execute("""
                SELECT 
                    indexname, 
                    indexdef 
                FROM pg_indexes 
                WHERE tablename = 'documents' 
                AND indexdef LIKE '%embedding%'
            """)
            
            indexes = cursor.fetchall()
            print("ğŸ“Š å‘é‡ç´¢å¼•ä¿¡æ¯:")
            for idx in indexes:
                print(f"  ç´¢å¼•å: {idx[0]}")
                print(f"  å®šä¹‰: {idx[1][:100]}...")
                print()
            
            return indexes
            
        except Exception as e:
            print(f"âŒ è·å–ç´¢å¼•ä¿¡æ¯å¤±è´¥: {e}")
            return []
        finally:
            if conn:
                conn.close()

# é«˜çº§æœç´¢åŠŸèƒ½
class AdvancedVectorSearch(VectorSearchManager):
    def hybrid_search(self, 
                    query_embedding: List[float],
                    keyword: str = None,
                    collection_name: str = None,
                    top_k: int = 10,
                    similarity_weight: float = 0.7,
                    keyword_weight: float = 0.3) -> List[Dict]:
        """
        æ··åˆæœç´¢ï¼šå‘é‡ç›¸ä¼¼åº¦ + å…³é”®è¯åŒ¹é…
        
        Args:
            query_embedding: æŸ¥è¯¢å‘é‡
            keyword: å…³é”®è¯
            similarity_weight: å‘é‡ç›¸ä¼¼åº¦æƒé‡
            keyword_weight: å…³é”®è¯åŒ¹é…æƒé‡
        """
        embedding_str = self._format_vector(query_embedding)
        
        query = """
        WITH vector_scores AS (
            SELECT 
                id,
                1 - (embedding <=> %s) as vector_score
            FROM documents
            {collection_filter}
        ),
        keyword_scores AS (
            SELECT 
                id,
                CASE 
                    WHEN subject ILIKE %s OR content ILIKE %s THEN 1.0
                    ELSE 0.0
                END as keyword_score
            FROM documents
            {collection_filter}
        )
        SELECT 
            d.id,
            d.collection_name,
            d.subject,
            d.content,
            d.metadata,
            (vs.vector_score * %s + ks.keyword_score * %s) as combined_score,
            vs.vector_score,
            ks.keyword_score
        FROM documents d
        JOIN vector_scores vs ON d.id = vs.id
        JOIN keyword_scores ks ON d.id = ks.id
        ORDER BY combined_score DESC
        LIMIT %s
        """
        
        collection_filter = f"WHERE collection_name = %s" if collection_name else ""
        keyword_pattern = f"%{keyword}%" if keyword else "%%"
        
        params = [embedding_str]
        if collection_name:
            params.extend([collection_name, collection_name])
        
        params.extend([keyword_pattern, keyword_pattern, similarity_weight, keyword_weight, top_k])
        
        try:
            conn = psycopg2.connect(self.connection_string)
            cursor = conn.cursor()
            
            query = query.format(collection_filter=collection_filter)
            cursor.execute(query, tuple(params))
            
            results = cursor.fetchall()
            columns = [desc[0] for desc in cursor.description]
            
            return [dict(zip(columns, row)) for row in results]
            
        except Exception as e:
            print(f"âŒ æ··åˆæœç´¢å¤±è´¥: {e}")
            return []
        finally:
            if conn:
                conn.close()